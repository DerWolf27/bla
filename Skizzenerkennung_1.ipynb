{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports needed libraries\n",
    "import os\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initalize picture variable height/ width/ batch size\n",
    "img_height = 28\n",
    "img_width = 28\n",
    "#The batch size defines the number of samples that will be propagated through the network\n",
    "batch_size = 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Simple Keras sequential models --> Creating Custom dataset for images is the main task of the programm\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        layers.Input((28, 28, 1)),\n",
    "        layers.Conv2D(16, 3, padding=\"same\"),\n",
    "        layers.Conv2D(32, 3, padding=\"same\"),\n",
    "        layers.MaxPooling2D(),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(10),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 110 files belonging to 2 classes.\n",
      "Using 99 files for training.\n"
     ]
    }
   ],
   "source": [
    "#----------------------------------------------------------------\n",
    "#This method works with images structured in different subfolders\n",
    "#----------------------------------------------------------------\n",
    "\n",
    "#Creating dataset from directory --> will be in a tensorflow dataset format with 'image_dataset_from_directory'\n",
    "ds_train = tf.keras.preprocessing.image_dataset_from_directory(\"C:/Users/janni/OneDrive/Desktop/Bachelorprojekt\",\n",
    "    #That simple means that the labels are inferred in alphabetical order from subfolder\n",
    "    labels=\"inferred\",\n",
    "    # You got different options for  --> int, categorical vector, binary\n",
    "    label_mode=\"int\",  \n",
    "    # class_names=['0', '1', '2', '3', ...] #optional\n",
    "    #Specify the color for the dataset as grayscale or RGB\n",
    "    color_mode=\"grayscale\",\n",
    "    #Specify the batchsize for the dataset as inilized at the top\n",
    "    batch_size=batch_size,\n",
    "    #Specify the image size for the dataset as initilized variable at the top\n",
    "    #Reshape if not in this size\n",
    "    image_size=(img_height, img_width),\n",
    "    #Shuffle the data in the dataset randomly  \n",
    "    shuffle=True,\n",
    "    #Seed is important when you split the data in trainingset an validationset\n",
    "    #Important when you want the same set everytime you run the code\n",
    "    seed=123,\n",
    "    #Means that 10% of the images are going to be in the validationsdata\n",
    "    validation_split=0.1,\n",
    "    #to be sure thats teh training we subset = training\n",
    "    subset=\"training\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 110 files belonging to 2 classes.\n",
      "Using 11 files for validation.\n"
     ]
    }
   ],
   "source": [
    "#Basically the Validations set ist created like the trainingset\n",
    "ds_validation = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    \"C:/Users/janni/OneDrive/Desktop/Bachelorprojekt\",\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"int\",  # categorical, binary\n",
    "    # class_names=['0', '1', '2', '3', ...]\n",
    "    color_mode=\"grayscale\",\n",
    "    batch_size=batch_size,\n",
    "    image_size=(img_height, img_width),  # reshape if not in this size\n",
    "    shuffle=True,\n",
    "    seed=123,\n",
    "    validation_split=0.1,\n",
    "    subset=\"validation\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------------------------------------------------------------------\n",
    "# One Method for data agumentation training\n",
    "#-------------------------------------------------------------------------------------\n",
    "# #Simple example for data agumentation method\n",
    "# def augment(x, y):\n",
    "#     image = tf.image.random_brightness(x, max_delta=0.05)\n",
    "#     return image, y\n",
    "# ds_train = ds_train.map(augment)\n",
    "# # You want to train on this above for Custom Loops\n",
    "# for epochs in range(8):\n",
    "#     for x, y in ds_train:\n",
    "#         # train here\n",
    "#         pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------------------------------------------------\n",
    "#Another method for training\n",
    "#----------------------------------------------------------------------------------\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(),\n",
    "    loss=[keras.losses.SparseCategoricalCrossentropy(from_logits=True),],\n",
    "    metrics=[\"accuracy\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "50/50 - 2s - loss: 50.5865 - accuracy: 0.6566 - 2s/epoch - 30ms/step\n",
      "Epoch 2/8\n",
      "50/50 - 1s - loss: 5.9345 - accuracy: 0.7677 - 663ms/epoch - 13ms/step\n",
      "Epoch 3/8\n",
      "50/50 - 1s - loss: 11.9112 - accuracy: 0.6667 - 644ms/epoch - 13ms/step\n",
      "Epoch 4/8\n",
      "50/50 - 1s - loss: 3.9653 - accuracy: 0.8485 - 579ms/epoch - 12ms/step\n",
      "Epoch 5/8\n",
      "50/50 - 1s - loss: 1.3772 - accuracy: 0.8990 - 601ms/epoch - 12ms/step\n",
      "Epoch 6/8\n",
      "50/50 - 1s - loss: 1.6371 - accuracy: 0.8485 - 612ms/epoch - 12ms/step\n",
      "Epoch 7/8\n",
      "50/50 - 0s - loss: 1.3785 - accuracy: 0.9091 - 498ms/epoch - 10ms/step\n",
      "Epoch 8/8\n",
      "50/50 - 0s - loss: 1.8502 - accuracy: 0.8889 - 488ms/epoch - 10ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x232ab0a7e20>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(ds_train, epochs=8, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#It will find a for example 50 files and will use 45 for training  \n",
    "#It will find a for example 50 files and will use 5 for training \n",
    "#to be clear the 45 of training will not be the same 5 for validation!!! (Those pics are unique)\n",
    "#After a certain period of epoche you will have a accurancy of 100%\n",
    "#That means we overfit to this 45 training examples\n",
    "#\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b710c1597876a07bd69decd94522cf419675e48532af5724bcb09ded2cbc0f9d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
